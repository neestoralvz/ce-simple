# Capture-Learnings - Intelligent Post-Execution Learning System

## ğŸ¯ Purpose
Dual-phase learning capture system that automatically documents execution patterns during workflows and conducts intelligent user interviews post-execution based on learning value assessment. Includes systematic integrity validation for command system coherence.

## ğŸš€ Usage
**Auto-Triggered**: Activates automatically during analysis phase and post-execution
**Manual**: Execute `/capture-learnings [phase: process|results]`

## ğŸ”§ Implementation

### Dual-Phase Learning Architecture

#### Phase 1: Process Learning (Auto-Triggered During Analysis)
**WHEN**: Activated parallel to `/explore-codebase` and `/think-layers`
**WHAT**: Automatic pattern detection and decision documentation
**OUTPUT**: Enhanced context files with discovered patterns

**Auto-Capture Elements**:
- **Architectural Decisions**: Why specific approaches chosen over alternatives
- **Pattern Recognition**: New patterns discovered vs existing patterns applied
- **Problem Resolution**: Issues encountered and resolution strategies
- **Discovery Documentation**: Previously unknown aspects of codebase/domain
- **Decision Trees**: Alternative paths considered and rationale for choices

#### Phase 2: Results Learning (Post-Execution Decision Point)
**WHEN**: After workflow execution completion
**WHAT**: Intelligent assessment of interview necessity + dynamic user feedback
**OUTPUT**: Experience documentation and system improvement insights

### Intelligent Interview Decision Matrix

#### Learning Value Assessment (Conservative Bias)
**Historical Context Weighting**:
- Days since last interview: +1 point (max +3)
- Consecutive simple executions: +1 point per 3 executions
- Novel domain interactions: +2 points

**Execution Complexity Scoring**:
```
Sequential commands (>2): +2 points
Error resolution occurred: +2 points  
New patterns discovered: +2 points
Alternative strategies evaluated: +1 point
Unexpected execution time: +1 point
Novel tool combinations: +1 point
Context switching required: +1 point
```

**Decision Logic**: â‰¥4 points OR historical factor present â†’ Activate Interview

#### Dynamic Interview Generation
**Adaptive Question Count** (3-6 questions based on learning density):
- **Core Set (Always)**: 3 high-value questions based on execution patterns
- **Extended Set (Conditional)**: +1-3 questions when novel patterns detected
- **Quality Gate**: Stop when diminishing value detected or user certainty confirmed

**Context-Driven Question Pool**:
- **Process Effectiveness**: "Â¿El workflow siguiÃ³ la secuencia que esperabas?"
- **Result Quality**: "Â¿Los resultados coinciden con tu visiÃ³n inicial?"
- **Friction Points**: "Â¿Hubo algÃºn momento donde te sentiste perdido o confundido?"
- **Discovery Value**: "Â¿Aprendiste algo inesperado sobre tu cÃ³digo/dominio?"
- **Efficiency Assessment**: "Â¿QuÃ© cambiarÃ­as del proceso para la prÃ³xima vez?"
- **System Evolution**: "Â¿El resultado sugiere mejoras al sistema mismo?"

**Adaptive Selection Logic**:
- Select 3 highest-value questions based on execution patterns detected
- Add extended questions only when multiple novel patterns found
- Prioritize density over quantity for cognitive load optimization

### Learning Documentation Framework

#### Pattern Storage Enhancement
**Extend Existing Context Architecture**:
```
context/patterns/
â”œâ”€â”€ execution-patterns-[domain].md      # How workflows typically execute
â”œâ”€â”€ decision-patterns-[domain].md       # Why certain choices made repeatedly  
â”œâ”€â”€ friction-patterns-[domain].md       # Common obstacles and solutions
â””â”€â”€ discovery-patterns-[domain].md      # Learning insights and breakthroughs
```

#### Experience Integration
**User Feedback Integration**:
```
context/experience/
â”œâ”€â”€ workflow-effectiveness-[month].md   # Process efficiency insights
â”œâ”€â”€ expectation-reality-[month].md      # Outcome vs prediction analysis
â””â”€â”€ improvement-suggestions-[month].md  # User-driven enhancement ideas
```

### Parallel Agent Integration

#### Process Learning Agent (During Analysis)
**Deploy Parallel To**:
- `/explore-codebase` â†’ Capture structural discovery patterns
- `/think-layers` â†’ Document analysis decision progression  
- Web research â†’ Record external pattern validation insights

**Agent Objectives**:
1. **Decision Documentation**: Record why specific approaches chosen
2. **Pattern Classification**: Identify if discoveries are novel vs familiar
3. **Alternative Assessment**: Document considered but rejected options
4. **Context Enhancement**: Enrich existing context with meta-insights

#### Results Learning Agent (Post-Execution)
**Trigger Conditions**:
- Workflow execution marked complete
- Context files generated and consolidated
- Learning value assessment â‰¥4 points OR historical trigger active

**Agent Workflow**:
1. **Execution Analysis**: Review full workflow trace and outcomes
2. **Interview Generation**: Create dynamic questions based on execution patterns
3. **User Engagement**: Conduct structured feedback interview
4. **System Integrity Validation**: Verify command system coherence and reference integrity
5. **Insight Integration**: Enhance existing patterns with experience data

### System Integrity Validation Framework

#### Rational Validation Protocol
**WHEN**: Activated during Phase 2 when interview threshold exceeded (â‰¥4 learning points)
**WHY**: Validate the system that just executed the workflow when learning context is maximum
**HOW**: Intelligent reference analysis with gap detection and resolution recommendations

#### Validation Components

**Reference Integrity Check**:
- **Command Existence**: Verify all referenced commands in "See Also" sections actually exist
- **Chain Consistency**: Validate workflow chains are bidirectional and complete
- **Cross-Reference Health**: Ensure referenced files and sections are accessible
- **Trigger Logic**: Verify input/output trigger consistency across commands

**Gap Discovery System**:
```
ğŸ” INTEGRITY: Scanning command references from executed workflow
ğŸ“Š ANALYSIS: [X] commands checked, [Y] references validated
âš ï¸  GAPS: [N] missing references detected â†’ [list of gaps]
ğŸ”§ RECOMMENDATIONS: [Specific actions to resolve gaps]
```

**Validation Scope**:
- **Executed Commands**: Primary focus on commands used in current workflow
- **Referenced Network**: Secondary check on "See Also" and trigger chains
- **Critical Paths**: Verify essential workflow progressions are intact
- **Evidence-Based**: Only flag definitive issues, avoid false positives

#### Gap Resolution Framework

**Classification System**:
- **Critical Gap**: Missing command breaks workflow execution (like `/plan-execution`)
- **Reference Gap**: Broken cross-reference reduces navigation efficiency  
- **Chain Gap**: Incomplete workflow progression creates user confusion
- **Documentation Gap**: Inconsistent or outdated references in documentation

**Resolution Priority**:
1. **Immediate**: Critical gaps affecting workflow functionality
2. **High**: Reference gaps in frequently used commands
3. **Medium**: Chain gaps in secondary workflows
4. **Low**: Documentation gaps in rarely accessed sections

**Recommendation Engine**:
```
ğŸ¯ RESOLUTION RECOMMENDATIONS:
â”œâ”€â”€ Create missing command: [command-name] referenced in [N] locations
â”œâ”€â”€ Update references: Replace [old-ref] with [new-ref] in [files]
â”œâ”€â”€ Complete chain: Add [missing-link] to connect [workflow-a] â†’ [workflow-b]  
â””â”€â”€ Validate architecture: Review [command-set] for consistency
```

#### Integration with Learning System

**Contextual Validation**:
- **Workflow-Aware**: Focus validation on commands and patterns just experienced
- **Learning-Enhanced**: Use interview insights to inform gap priority assessment
- **Pattern-Integrated**: Document discovered gaps as system architecture patterns
- **User-Guided**: Include gap findings in overall learning capture and documentation

**Notification Integration**:
```
ğŸ” INTEGRITY: System validation initiated â†’ Workflow context analysis
ğŸ“Š VALIDATION: [X] commands verified, [Y] references checked
âš ï¸  DISCOVERY: [N] gaps identified â†’ [severity breakdown]
âœ… COMPLETION: System health documented â†’ Recommendations generated
```

### Learning Quality Assurance

#### Anti-Bias Learning Processing
**Neutral Pattern Documentation**:
- Focus on evidence-based observations over interpretations
- Document multiple perspectives when applicable  
- Separate factual patterns from subjective preferences
- Validate patterns through multiple execution instances

#### Progressive Learning Disclosure
**Context File Enhancement** (â‰¤200 lines max):
- Append insights to existing context files rather than creating new ones
- Cross-reference related patterns across domains
- Maintain maximum information density principles
- Enable pattern evolution tracking over time

### Notification Integration

#### Process Learning Notifications
```
ğŸ§  LEARNING: Pattern detection active â†’ [discovery-type] identified
ğŸ“š CAPTURE: Decision documented â†’ [pattern-category] updated  
ğŸ”— INTEGRATION: Context enhanced â†’ [context-file] enriched
```

#### Results Learning Notifications  
```
ğŸ¯ ASSESSMENT: Interview necessity evaluated â†’ [score]/10 points
ğŸ“Š DECISION: User interview activated â†’ [question-count] dynamic questions
ğŸ” INTEGRITY: System validation initiated â†’ [X] commands from executed workflow
âš ï¸  GAPS: [N] system gaps discovered â†’ [priority breakdown]
âœ… COMPLETION: Learning + validation captured â†’ [pattern-count] patterns enhanced
ğŸš« SKIP: Auto-documentation â†’ Low learning value detected
```

## âš¡ Triggers

### Input Triggers
**Auto-Process**: During `/explore-codebase`, `/think-layers`, complex analysis
**Auto-Results**: Post-execution of any workflow sequence
**Manual**: Direct command execution for specific learning focus

### Output Triggers  
**Enhanced Context**: Updated pattern and discovery documentation
**User Interview**: Dynamic feedback collection when learning value detected
**System Validation**: Integrity check and gap discovery when interview triggered
**Pattern Evolution**: Cross-reference updates and trend identification

### Success Patterns
**Process Learning**: Novel patterns documented, decisions traced, alternatives recorded
**Results Learning**: User insights captured, experience-reality gaps identified, improvement opportunities documented
**System Validation**: Command integrity verified, gaps discovered and prioritized, resolution recommendations generated
**System Enhancement**: Learning patterns + integrity findings influence future workflow optimization

## ğŸ”— See Also

### Related Commands
- Integrates with `/start` for intelligent learning activation
- Enhances `/explore-codebase` with pattern detection capabilities
- Extends `/think-layers` with decision documentation
- Coordinates with all workflow commands for post-execution learning

### System Integration
- Follows anti-bias protocols for neutral learning documentation  
- Maintains simplicity principles through context file enhancement vs creation
- Integrates with existing notification and progress tracking systems
- Preserves cross-reference architecture and progressive disclosure standards

---

**CRITICAL**: This command operates in dual-phase mode with integrated system integrity validation following maximum rationality principles. Process learning must not interfere with execution efficiency while results learning should maximize user insight value through intelligent interview activation and systematic gap discovery.