# Comando: /analyze-performance

> **Ubicaci√≥n:** `.claude/commands/analyze-performance.md`

Analiza el rendimiento del sistema usando profilers especializados que identifican bottlenecks y oportunidades de optimizaci√≥n

## PROTOCOLO DE EJECUCI√ìN

### FASE 1: CONFIGURACI√ìN DE AN√ÅLISIS

DEFINIR par√°metros de performance:
- M√©tricas objetivo (latencia, throughput, memoria)
- Entorno de an√°lisis (desarrollo, staging, producci√≥n)
- Carga esperada (usuarios concurrentes, RPS)
- SLAs/SLOs actuales si existen

### FASE 2: DESPLIEGUE DE PROFILERS ESPECIALIZADOS

DESPLEGAR 6 SUBAGENTES PROFILERS EN PARALELO:

```bash
# USAR TASK TOOL PARA EJECUCI√ìN PARALELA

TASK 1 - ‚ö° Profiler de Backend:
MEDIR:
- Tiempo de respuesta por endpoint
- Queries de base de datos lentas
- CPU y memoria por proceso
- I/O operations (disk, network)
ANALIZAR:
- Hot paths en el c√≥digo
- N+1 queries
- Memory leaks
- Blocking operations
IDENTIFICAR:
- Funciones que consumen m√°s CPU
- Endpoints m√°s lentos
- Queries sin √≠ndices
ENTREGAR: Perfil detallado con flamegraphs

TASK 2 - üé® Profiler de Frontend:
EVALUAR:
- First Contentful Paint (FCP)
- Largest Contentful Paint (LCP)
- Time to Interactive (TTI)
- Cumulative Layout Shift (CLS)
ANALIZAR:
- Bundle size y tree shaking
- Render performance
- JavaScript execution time
- Network waterfall
DETECTAR:
- Componentes que re-renderizan excesivamente
- Assets no optimizados
- Third-party scripts bloqueantes
ENTREGAR: Lighthouse report + recomendaciones

TASK 3 - üóÑÔ∏è Profiler de Base de Datos:
EXAMINAR:
- Query execution plans
- √çndices faltantes o no utilizados
- Lock contention
- Connection pool usage
MEDIR:
- Queries m√°s lentas (top 20)
- Tablas m√°s grandes sin particionamiento
- Cache hit ratio
- Transacciones largas
OPTIMIZAR:
- Sugerir √≠ndices necesarios
- Identificar queries para optimizar
- Recomendar particionamiento
ENTREGAR: Plan de optimizaci√≥n de DB

TASK 4 - üîÑ Profiler de Cach√©:
ANALIZAR:
- Hit/miss ratio por tipo de cache
- TTL configuration
- Cache invalidation patterns
- Memory usage
EVALUAR:
- Redis/Memcached performance
- CDN cache effectiveness
- Browser cache headers
- Application-level caching
IDENTIFICAR:
- Datos no cacheados que deber√≠an
- Over-caching (datos stale)
- Cache stampede risks
ENTREGAR: Estrategia de caching mejorada

TASK 5 - üåê Profiler de Red:
MEDIR:
- Latencia entre servicios
- Bandwidth usage
- Connection pooling
- DNS lookup time
ANALIZAR:
- API payload sizes
- Compression usage
- Keep-alive connections
- HTTP/2 adoption
DETECTAR:
- Chatty APIs (muchas llamadas peque√±as)
- Missing compression
- Inefficient protocols
ENTREGAR: Optimizaciones de red

TASK 6 - üìä Profiler de Infraestructura:
MONITOREAR:
- CPU usage por servicio
- Memory patterns
- Disk I/O
- Container/VM metrics
EVALUAR:
- Auto-scaling configuration
- Resource limits
- Load balancer health
- Service mesh overhead
IDENTIFICAR:
- Over/under provisioning
- Resource contention
- Inefficient deployments
ENTREGAR: Recomendaciones de infra

# EJECUTAR TODAS LAS TASKS SIMULT√ÅNEAMENTE
```

### FASE 3: S√çNTESIS Y PRIORIZACI√ìN

CONSOLIDAR m√©tricas y generar plan de acci√≥n:

```markdown
## ‚ö° AN√ÅLISIS DE PERFORMANCE COMPLETO

### Resumen Ejecutivo
- **Performance Score**: [X]/100
- **P95 Latencia**: [XXXms]
- **Throughput**: [XXXX RPS]
- **Principales Bottlenecks**: [top 3]

### üìä M√©tricas Clave

#### Backend Performance
| M√©trica | Actual | Target | Status |
|---------|--------|--------|--------|
| P50 Latencia | 45ms | 50ms | ‚úÖ |
| P95 Latencia | 320ms | 200ms | ‚ùå |
| P99 Latencia | 890ms | 500ms | ‚ùå |
| CPU Usage | 78% | 70% | ‚ö†Ô∏è |
| Memory Usage | 3.2GB | 4GB | ‚úÖ |

#### Frontend Performance
| M√©trica | Desktop | Mobile | Target |
|---------|---------|---------|--------|
| LCP | 2.1s | 4.2s | <2.5s |
| FID | 45ms | 120ms | <100ms |
| CLS | 0.05 | 0.12 | <0.1 |
| TTI | 3.4s | 6.8s | <3.8s |

### üî• Top Bottlenecks Identificados

#### 1. Queries N+1 en API de usuarios
- **Impacto**: +200ms en P95
- **Ubicaci√≥n**: `services/user/getProfile.js`
- **Soluci√≥n**:
  ```javascript
  // Actual (N+1)
  const users = await User.findAll();
  for (const user of users) {
    user.posts = await Post.findByUserId(user.id);
  }
  
  // Optimizado
  const users = await User.findAll({
    include: [{
      model: Post,
      as: 'posts'
    }]
  });
  ```

#### 2. Bundle JavaScript demasiado grande
- **Impacto**: +2s en TTI mobile
- **Tama√±o actual**: 1.2MB (350KB gzipped)
- **Soluci√≥n**:
  - Code splitting por ruta
  - Lazy loading de componentes pesados
  - Tree shaking de lodash
  - Eliminar moment.js por date-fns

#### 3. Falta de √≠ndices en queries frecuentes
- **Impacto**: +150ms en queries de b√∫squeda
- **Queries afectadas**: 5 queries principales
- **Soluci√≥n**:
  ```sql
  -- √çndices recomendados
  CREATE INDEX idx_users_email_active ON users(email, active);
  CREATE INDEX idx_posts_user_created ON posts(user_id, created_at DESC);
  CREATE INDEX idx_orders_status_date ON orders(status, order_date);
  ```

### üóÑÔ∏è Optimizaciones de Base de Datos
[S√≠ntesis del profiler de DB]

#### Queries M√°s Lentas
1. **getUserDashboardData**: 890ms avg
   - Missing index on analytics table
   - Suggestion: Materialized view

2. **searchProducts**: 450ms avg
   - Full table scan
   - Suggestion: Full-text search index

#### Plan de √çndices
```sql
-- Prioridad Alta
CREATE INDEX CONCURRENTLY idx_analytics_user_date 
ON analytics(user_id, created_date) 
WHERE deleted_at IS NULL;

-- Prioridad Media
CREATE INDEX idx_products_search 
ON products USING gin(to_tsvector('english', name || ' ' || description));
```

### üîÑ Estrategia de Caching
[S√≠ntesis del profiler de cach√©]

#### Cache Hit Ratios Actuales
- Redis: 67% (objetivo: 85%)
- CDN: 45% (objetivo: 70%)
- Browser: 23% (objetivo: 60%)

#### Mejoras Recomendadas
1. **Redis**:
   - Aumentar TTL para datos de usuario: 5min ‚Üí 15min
   - Implementar cache warming para dashboards
   - Cache de queries agregadas

2. **CDN**:
   - Configurar cache para assets est√°ticos
   - Implementar cache keys inteligentes
   - Edge caching para APIs geo-distribuidas

### üåê Optimizaciones de Red
[S√≠ntesis del profiler de red]
- Implementar compression Brotli (30% mejor que gzip)
- Reducir payloads de API (pagination, field selection)
- HTTP/2 push para critical resources
- Connection pooling para microservicios

### üìà Plan de Optimizaci√≥n Priorizado

#### Sprint 1 (Quick Wins) - Ganancia esperada: 40%
1. [ ] Agregar √≠ndices faltantes (2h)
2. [ ] Implementar eager loading para N+1 (4h)
3. [ ] Habilitar Brotli compression (1h)
4. [ ] Aumentar cache TTLs (1h)

#### Sprint 2 (Frontend) - Ganancia esperada: 30%
1. [ ] Code splitting por rutas (8h)
2. [ ] Optimizar im√°genes con next-gen formats (4h)
3. [ ] Lazy load componentes pesados (6h)
4. [ ] Implementar service worker (8h)

#### Sprint 3 (Backend) - Ganancia esperada: 25%
1. [ ] Refactorizar queries lentas (12h)
2. [ ] Implementar connection pooling (6h)
3. [ ] Optimizar serializaci√≥n JSON (4h)
4. [ ] Agregar cache warming (8h)

### üéØ Impacto Proyectado
Con todas las optimizaciones implementadas:
- P95 Latencia: 320ms ‚Üí 140ms (-56%)
- LCP Mobile: 4.2s ‚Üí 2.3s (-45%)
- Throughput: +65% capacidad
- Costo infra: -30% por optimizaci√≥n de recursos
```

### FASE 4: MONITOREO CONTINUO

ESTABLECER m√©tricas de seguimiento:
```bash
# Configurar dashboards
mkdir -p monitoring/performance
cp [m√©tricas] monitoring/performance/baseline.json

# Alertas autom√°ticas
echo "[alertas]" > monitoring/alerts/performance.yaml
```

## VARIANTES DEL COMANDO

### An√°lisis Espec√≠fico
```bash
/analyze-performance --component=api
# Solo analiza performance del API

/analyze-performance --type=frontend
# Solo m√©tricas de frontend

/analyze-performance --env=production
# An√°lisis en ambiente espec√≠fico
```

### An√°lisis Comparativo
```bash
/analyze-performance --compare-with=last-week
# Compara con per√≠odo anterior

/analyze-performance --load-test
# Ejecuta con carga simulada

/analyze-performance --profile=memory
# Enfoque en memory leaks
```

## INTEGRACI√ìN CON OTROS COMANDOS

Este comando es invocado por:
- **`/refactor-smart`**: Para medir impacto de refactoring
- **`/pre-deploy`**: Validar que no hay regresiones
- **`/generate-prp`**: Para features que requieren performance
- **`/scale-planning`**: Para decisiones de infraestructura

## OUTPUT EJEMPLO

```markdown
‚ö° An√°lisis de Performance completado en 92 segundos

PROYECTO: E-commerce Platform
SCORE: 68/100 (Necesita optimizaci√≥n)
P95: 320ms (target: 200ms)

üî• TOP 3 BOTTLENECKS:
1. N+1 queries en cart API (+180ms)
2. Uncompressed assets (+1.5s load)
3. No connection pooling (+80ms)

üí∞ ROI ESTIMADO:
- Quick wins: -40% latencia en 1 sprint
- Conversi√≥n estimada: +2.3%
- Ahorro infra: $1,200/mes

üéØ ACCI√ìN RECOMENDADA:
Ejecutar `/generate-prp performance-quick-wins.md`
```

## HERRAMIENTAS COMPLEMENTARIAS

1. **APM**: NewRelic, DataDog, AppDynamics
2. **Profiling**: Chrome DevTools, pprof, flamegraphs
3. **Load Testing**: k6, JMeter, Gatling
4. **Monitoring**: Prometheus + Grafana
5. **Real User Monitoring**: Google Analytics, Sentry