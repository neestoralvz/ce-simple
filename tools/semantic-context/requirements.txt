# Semantic Context Retrieval System Requirements
# Production-ready dependencies for 2025 research-backed implementation

# Core Dependencies (Required)
numpy>=1.24.0
scipy>=1.10.0
scikit-learn>=1.3.0

# Advanced Search & Embeddings (Highly Recommended)
sentence-transformers>=2.2.2
faiss-cpu>=1.7.4
rank-bm25>=0.2.2

# Model Support
torch>=2.0.0
transformers>=4.30.0
tiktoken>=0.5.0

# Text Processing & Analysis (Optional but Recommended)
nltk>=3.8.1
textstat>=0.7.3
spacy>=3.6.0

# Visualization & Monitoring (Optional)
matplotlib>=3.7.0
seaborn>=0.12.0
plotly>=5.15.0

# System Monitoring (Optional)
psutil>=5.9.0
memory-profiler>=0.61.0

# Development & Testing (Optional)
pytest>=7.4.0
pytest-asyncio>=0.21.0
pytest-benchmark>=4.0.0
black>=23.7.0
flake8>=6.0.0

# Additional Utilities
python-dateutil>=2.8.2
pydantic>=2.0.0
tenacity>=8.2.0

# Optional AI/ML Enhancements
openai>=1.0.0  # For GPT-based enhancements (optional)
anthropic>=0.3.0  # For Claude integration (optional)

# Installation Notes:
#
# Minimal Installation (Core functionality):
#   pip install numpy scipy scikit-learn
#
# Recommended Installation (Full features):
#   pip install -r requirements.txt
#
# GPU Support (if available):
#   Replace faiss-cpu with faiss-gpu
#   Ensure CUDA compatibility with torch
#
# Apple Silicon Optimization:
#   pip install --upgrade --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
#
# Memory-Constrained Environments:
#   Use lighter models in embedding_manager.py
#   Reduce batch_size and max_seq_length in configurations
#
# Production Deployment:
#   Consider using sentence-transformers with ONNX runtime
#   Use quantized models for memory efficiency
#   Enable GPU acceleration where available